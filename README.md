BEARscc - Bayesian ERCC Assessment of Robustness  
================================================

# Summary
Single-cell transcriptome sequencing data are subject to substantial technical variation and batch effects that can confound the classification of cellular sub-types. Unfortunately, current clustering algorithms don't account for this uncertainty. To address this shortcoming, we have developed a noise perturbation algorithm called **BEARscc** that is designed to determine the extent to which classifications by existing clustering algorithms are robust to observed technical variation.

**BEARscc** makes use of ERCC spike-in measurements to model technical variance as a function of gene expression and technical dropout effects on lowly expressed genes. In our benchmarks, we found that BEARscc accurately models read count fluctuations and drop-out effects across transcripts with diverse expression levels. Applying our approach to publicly available single-cell transcriptome data of mouse brain and intestine, we have demonstrated that BEARscc identified cells that cluster consistently, irrespective of technical variation:

![BEARscc consensus cluster](images/example_consensus.png)

# Installation

Installing BEARscc is easy. You can download a binary package [here](https://bitbucket.org/ludwigbioinf/bearscc/raw/ebfe054be6bac0082adc97ee6774a0b69b32c9c4/builds/BEARscc_0.1.0.tgz). You can then use `install.packages` as normal, but give it the location of the downloaded file:

```R
 install.packages('BEARscc_0.1.0.tgz')
 ```
 

# Usage

Here we provide a limited illustrative example of BEARscc on example data. A comprehensive vignette is being drafted and will be available in the near future. 

In R, load a single cell data table and ERCC known concentrations:

`data.counts.dt<- fread("example/brain_control_example.tsv")` <br>
`ERCC.meta.dt<- fread("example/ERCC.meta.tsv")`

Seperate ERCC observations into a `data.frame` and transfrom counts and ERCC known concentration `data.table` into `data.frame`.

`ERCC.counts.df<-data.frame(data.counts.dt[GENE_ID%like%"ERCC-",], row.names="GENE_ID")` <br>
`data.counts.df<-data.frame(data.dt, row.names = "GENE_ID")` <br>
`ÃˆRCC.meta.df<-data.frame(ERCC.meta.dt, row.names="ERCC_ID")` <br>

Estimate noise inputting ERCC known concentrations, and both endogenous and spike-in counts matrices into `estimate_noiseparameters()` function.

`results<-estimate_noiseparameters(ERCC.counts.df,ERCC.meta.df, data.counts.df,granularity=30, write.noise.model=TRUE, file="noise_estimation", model_view=c("Observed","Optimized"))`

Several options exist:

`granularity` determines the number of bins for comparison of the quality of fit between the mixed-model and observed data for each alpha. This should be set lower for small datasets and higher for datasets with more observations<br>

`write.noise.model=TRUE` outputs two tab-delimited files containing the dropout effects and noise model parameters; this allows users to apply the noise generation on a seperate high compute node. <br>

`plot==TRUE` will plot all linear fits and individual ERCCs distributions across samples, where `model_view=c("Observed", "Optimized", "Poisson", "Neg. Binomial"` determines the statistical distributions that should be plotted for the ERCC plots. `file="./Rplot"` determines the root name for all plots, which write to the current working directory unless a path is contained in the root name.  <br>


Following estimation of noise the parameters are used to generate a noise-injected counts matrix. 

`noisy_counts.list<-create_noiseinjected_counts(results, n=10)`

`results` is the list object generated by the function `estimate_noiseparameters()` and the variable `n` is the desired number of clusters. For larger datasets it is recommended that the user set `write.noise.model=TRUE` and copy the written bayesian drop-out and noise estimate files with the observed counts table to a high powered computing environment. The script `HPC_generate_noise_matrices` contains `create_noiseinjected_counts()` functions that are adapted to a parallel environment along with suggested code, which is commented out for user-modification. The script generates seperate noise-injected counts files, which can be loaded into R as a list or re-clustered seperately in a high powered compute environment. 

After generating noise-injected counts tables, these should be re-clustered using the clustering method applied to the original dataset. For simplicity, here we use hiearchical clustering on a pearson correlation metric. 









 
# License
 This software is made available under the terms of the [GNU General Public License v3](http://www.gnu.org/licenses/gpl-3.0.html)

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
